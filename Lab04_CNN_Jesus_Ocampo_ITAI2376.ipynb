{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Building a CNN for MNIST Handwritten Digit Classification\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome! In this assignment, you will build a Convolutional Neural Network (CNN) to classify handwritten digits from the famous MNIST dataset. This dataset is a classic in the field of computer vision and provides a great starting point for understanding image classification with deep learning.\n",
        "\n",
        "This notebook is structured to guide you step-by-step through the process. You will load the data, preprocess it, define a CNN model, train it, and evaluate its performance.  Throughout the assignment, you will have opportunities to experiment and deepen your understanding of the concepts.\n",
        "\n",
        "Remember to:\n",
        "\n",
        "*   **Read all instructions carefully.**\n",
        "*   **Execute the code cells in order.**\n",
        "*   **Fill in the missing code sections marked as \"Students: Fill in the blanks\".**\n",
        "*   **Answer the reflection questions in the designated Markdown cell.**\n",
        "*   **Experiment and explore!**  Change parameters, layers, and observe the effects.\n",
        "\n",
        "Let's get started and build our MNIST digit classifier!\n",
        "\n",
        "## Section 1: Setting Up - Imports\n",
        "\n",
        "Before we dive into building our CNN, we need to import the necessary libraries.  These libraries provide pre-built tools and functions that will make our work much easier.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully review the code cell below.** It imports libraries from TensorFlow and Keras, which are powerful frameworks for building and training neural networks.\n",
        "2.  **Execute the code cell by selecting it and pressing [Shift + Enter] (or the \"Run\" button).**\n",
        "3.  **Ensure there are no error messages after running the cell.** If you encounter errors, double-check that you have TensorFlow and Keras installed in your environment."
      ],
      "metadata": {
        "id": "fK46PtzUyabH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "import time\n",
        "import datetime"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "xN_gVhnXyabK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Imports:**\n",
        "\n",
        "*   **`tensorflow as tf` and `keras`:** TensorFlow is the main deep learning framework, and Keras is its high-level API that simplifies building and training models. We import TensorFlow as `tf` and Keras directly for easy access to their functionalities.\n",
        "*   **`from tensorflow.keras import layers`:**  This imports the `layers` module from Keras, which provides various layers for building neural networks (like convolutional layers, dense layers, etc.).\n",
        "*   **`from tensorflow.keras.datasets import mnist`:**  This imports the MNIST dataset directly from Keras datasets.  This is very convenient for loading and using the MNIST data.\n",
        "*   **`from tensorflow.keras.utils import to_categorical`:**  This imports the `to_categorical` function, which we will use to perform one-hot encoding of our labels.\n",
        "\n",
        "## Section 2: Data Loading and Preprocessing\n",
        "\n",
        "In this section, we will load the MNIST dataset and prepare it for training our CNN model.  Preprocessing steps are crucial to ensure our data is in the right format for the model to learn effectively.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Read through the code in the cell below.**  Understand how it loads the MNIST dataset and what preprocessing steps are applied.\n",
        "2.  **Execute the code cell.**\n",
        "3.  **Examine the comments in the code** to understand each preprocessing step in detail."
      ],
      "metadata": {
        "id": "jXAItJ1RyabL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Cell 2: Data Loading and Preprocessing\n",
        "# -------------------------------\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to the range [0, 1]\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Reshape the data to include the channel dimension (28x28x1)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "id": "OCi441G0yabL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "317f5c14-5105-4de6-c07e-eaea6bb9a5fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Data Preprocessing:**\n",
        "\n",
        "*   **Loading the MNIST dataset:** `mnist.load_data()` loads the MNIST dataset, which is already split into training and testing sets (`(x_train, y_train), (x_test, y_test)`). `x_train` and `x_test` contain the images (pixel data), and `y_train` and `y_test` contain the corresponding labels (digits 0-9).\n",
        "*   **Normalization:** `x_train = x_train.astype(\"float32\") / 255.0` and `x_test = x_test.astype(\"float32\") / 255.0` normalize the pixel values.  Pixel values in images are typically in the range 0-255. Dividing by 255 scales them to the range 0-1. This normalization helps the neural network train faster and more effectively.\n",
        "*   **Adding Channel Dimension:** `x_train = x_train.reshape(-1, 28, 28, 1)` and `x_test = x_test.reshape(-1, 28, 28, 1)` reshape the data to add a channel dimension.  Even though MNIST images are grayscale (single channel), CNNs in Keras expect input data to have a channel dimension.  We reshape from `(number_of_images, 28, 28)` to `(number_of_images, 28, 28, 1)`. The `-1` in `reshape` means \"infer the dimension based on the size of the array.\"\n",
        "*   **One-Hot Encoding:** `y_train = to_categorical(y_train, num_classes)` and `y_test = to_categorical(y_test, num_classes)` perform one-hot encoding on the labels.  Instead of representing the digit '3' as a single number, one-hot encoding converts it into a vector `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, where the 4th position (index 3) is 'hot' (value 1), and all other positions are 'cold' (value 0). This is a standard way to represent categorical labels for neural networks in multi-class classification problems. `num_classes = 10` specifies that we have 10 classes (digits 0-9).\n",
        "\n",
        "## Section 3: Model Definition - Building the CNN\n",
        "\n",
        "Now we will define the architecture of our Convolutional Neural Network (CNN).  You will be building a sequential model using Keras layers.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Carefully examine the code in the cell below.** Notice the structure of the `keras.Sequential` model.\n",
        "2.  **Fill in the missing parts** marked with `# Students: Fill in the blanks` to complete the model definition.\n",
        "3.  **Experiment!** You are encouraged to try different configurations for the layers, such as changing the number of filters in the convolutional layers, or adding more layers."
      ],
      "metadata": {
        "id": "UNkWB4hvyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Cell 3: Data Augmentation\n",
        "# -------------------------------\n",
        "# Set up data augmentation to expand the training dataset\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,         # Rotate images up to 10 degrees\n",
        "    zoom_range=0.1,            # Zoom images up to 10%\n",
        "    width_shift_range=0.1,     # Shift images horizontally by 10%\n",
        "    height_shift_range=0.1     # Shift images vertically by 10%\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Model Definition\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28, 1)),  # Input layer for 28x28 grayscale images\n",
        "\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Flatten the output and add Dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "FFOe2fviyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Layers:**\n",
        "\n",
        "*   **`keras.Input(shape=(28, 28, 1))`:** This is the input layer of our model. It specifies the shape of the input images, which are 28x28 pixels with 1 channel (grayscale).\n",
        "*   **`layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")`:** This is a 2D Convolutional layer.\n",
        "    *   `32`: This is the number of filters (also called kernels). Each filter learns to detect specific features in the input image.\n",
        "    *   `kernel_size=(3, 3)`: This defines the size of the convolutional filter as 3x3 pixels.\n",
        "    *   `activation=\"relu\"`:  ReLU (Rectified Linear Unit) is the activation function. It introduces non-linearity into the model, allowing it to learn complex patterns.\n",
        "*   **`layers.MaxPooling2D(pool_size=(2, 2))`:** This is a Max Pooling layer.\n",
        "    *   `pool_size=(2, 2)`:  It reduces the spatial dimensions of the feature maps by taking the maximum value within each 2x2 window. This helps to reduce the number of parameters, control overfitting, and make the model more robust to small shifts and distortions in the input.\n",
        "*   **`layers.Flatten()`:** This layer flattens the 2D feature maps from the convolutional and pooling layers into a 1D vector. This is necessary to connect the convolutional part of the network to the fully connected (Dense) layers.\n",
        "*   **`layers.Dropout(0.5)`:** This is a Dropout layer.\n",
        "    *   `0.5`: This sets the dropout rate to 50%. During training, this layer randomly sets 50% of the input units to 0 at each update. This is a regularization technique that helps to prevent overfitting.\n",
        "*   **`layers.Dense(num_classes, activation=\"softmax\")`:** This is the output Dense (fully connected) layer.\n",
        "    *   `num_classes`:  This is set to 10 because we have 10 classes (digits 0-9).\n",
        "    *   `activation=\"softmax\"`: Softmax activation ensures that the output values are probabilities, and they sum up to 1 across all classes.  The output will be a vector of 10 probabilities, where each probability represents the model's confidence that the input image belongs to that specific digit class.\n",
        "\n",
        "## Section 4: Model Compilation - Choosing Loss and Optimizer\n",
        "\n",
        "Before we can train our model, we need to compile it.  Compilation involves choosing an optimizer, a loss function, and metrics to evaluate the model's performance.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for the `loss` and `optimizer` parameters in `model.compile()`.\n",
        "2.  **Choose an appropriate loss function and optimizer** for this multi-class classification problem.\n",
        "3.  **In the Markdown cell after the code, explain your choices.** Why are these choices suitable for this task?"
      ],
      "metadata": {
        "id": "-x0iiCewyabM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with appropriate loss function and optimizer\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "YVr-ooXfyabM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Choices (To be filled by students in the reflection section):**\n",
        "\n",
        "*   **Loss Function:** You need to choose a loss function that is appropriate for multi-class classification. Think about what kind of error we are trying to minimize when classifying digits into 10 categories.\n",
        "*   **Optimizer:** You need to choose an optimizer that will efficiently update the model's weights to minimize the loss function.  Consider common optimizers used in deep learning.\n",
        "*   **Metrics:** We are using \"accuracy\" as a metric to evaluate the model's performance. Accuracy is a common metric for classification tasks, representing the percentage of correctly classified images.\n",
        "\n",
        "## Section 5: Model Training - Fitting the Model to the Data\n",
        "\n",
        "Now it's time to train our CNN model using the training data. Training involves feeding the training data to the model and adjusting its weights to minimize the loss function.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Examine the code cell below.** You need to fill in the blanks for `batch_size` and `epochs` in `model.fit()`.\n",
        "2.  **Choose appropriate values for `batch_size` and `epochs`.**\n",
        "3.  **Run the code cell to start training.** Observe the training progress, especially the loss and accuracy on both the training and validation sets.\n",
        "4.  **Experiment!** Change the `batch_size` and `epochs` and see how it affects the training process and the final performance."
      ],
      "metadata": {
        "id": "2R7iy69RyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Model Training\n",
        "\n",
        "# Callback Setup\n",
        "\n",
        "# Custom callback to log the duration of each epoch\n",
        "class TimeHistory(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start_time = time.time()\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        elapsed_time = time.time() - self.epoch_start_time\n",
        "        print(f\"Epoch {epoch + 1} took {elapsed_time:.2f} seconds\")\n",
        "\n",
        "# Early stopping callback to prevent overfitting by stopping training when the validation loss stops improving\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "# Model checkpoint callback to save the best model based on validation loss\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# TensorBoard callback for monitoring training metrics and visualizing the model architecture\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# Combine all callbacks into a list\n",
        "callbacks = [TimeHistory(), early_stop, checkpoint, tensorboard_callback]\n",
        "\n",
        "# Model Training\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 64\n",
        "epochs = 15\n",
        "\n",
        "# Train the model using the augmented data generator\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m935/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7984 - loss: 0.6131Epoch 1 took 32.88 seconds\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.03365, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 29ms/step - accuracy: 0.7987 - loss: 0.6121 - val_accuracy: 0.9883 - val_loss: 0.0336\n",
            "Epoch 2/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9531 - loss: 0.1795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 took 0.66 seconds\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.03365\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.9531 - loss: 0.1795 - val_accuracy: 0.9881 - val_loss: 0.0346\n",
            "Epoch 3/15\n",
            "\u001b[1m935/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9667 - loss: 0.1064Epoch 3 took 23.16 seconds\n",
            "\n",
            "Epoch 3: val_loss improved from 0.03365 to 0.02443, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - accuracy: 0.9667 - loss: 0.1063 - val_accuracy: 0.9910 - val_loss: 0.0244\n",
            "Epoch 4/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1497Epoch 4 took 1.30 seconds\n",
            "\n",
            "Epoch 4: val_loss improved from 0.02443 to 0.02295, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1497 - val_accuracy: 0.9920 - val_loss: 0.0230\n",
            "Epoch 5/15\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0794Epoch 5 took 38.00 seconds\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.02295\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0794 - val_accuracy: 0.9903 - val_loss: 0.0286\n",
            "Epoch 6/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0472Epoch 6 took 1.30 seconds\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.02295\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0472 - val_accuracy: 0.9909 - val_loss: 0.0273\n",
            "Epoch 7/15\n",
            "\u001b[1m935/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9796 - loss: 0.0658Epoch 7 took 39.66 seconds\n",
            "\n",
            "Epoch 7: val_loss improved from 0.02295 to 0.02181, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9796 - loss: 0.0658 - val_accuracy: 0.9931 - val_loss: 0.0218\n",
            "Epoch 8/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0073Epoch 8 took 0.73 seconds\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.02181\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9929 - val_loss: 0.0220\n",
            "Epoch 9/15\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9819 - loss: 0.0572Epoch 9 took 40.10 seconds\n",
            "\n",
            "Epoch 9: val_loss improved from 0.02181 to 0.02014, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9819 - loss: 0.0572 - val_accuracy: 0.9929 - val_loss: 0.0201\n",
            "Epoch 10/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0330Epoch 10 took 1.30 seconds\n",
            "\n",
            "Epoch 10: val_loss improved from 0.02014 to 0.02009, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0330 - val_accuracy: 0.9926 - val_loss: 0.0201\n",
            "Epoch 11/15\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.0557Epoch 11 took 22.54 seconds\n",
            "\n",
            "Epoch 11: val_loss improved from 0.02009 to 0.01936, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9824 - loss: 0.0557 - val_accuracy: 0.9934 - val_loss: 0.0194\n",
            "Epoch 12/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0033Epoch 12 took 1.30 seconds\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.01936\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9935 - val_loss: 0.0197\n",
            "Epoch 13/15\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0480Epoch 13 took 22.71 seconds\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.01936\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.9856 - loss: 0.0480 - val_accuracy: 0.9929 - val_loss: 0.0209\n",
            "Epoch 14/15\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0378Epoch 14 took 1.30 seconds\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.01936\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.0378 - val_accuracy: 0.9936 - val_loss: 0.0200\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "id": "UtpZIbTHyabN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0b62a719-3027-4f01-d657-eef21c0eec30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of Training Parameters:**\n",
        "\n",
        "*   **`batch_size`:** This determines the number of training samples processed in each mini-batch during training. A larger batch size can speed up training but might require more memory. A smaller batch size can lead to more noisy updates but might generalize better.\n",
        "*   **`epochs`:**  One epoch represents one complete pass through the entire training dataset.  More epochs can potentially lead to better training but also increase the risk of overfitting, where the model learns the training data too well and performs poorly on unseen data.\n",
        "*   **`validation_split=0.1`:**  This reserves 10% of the training data as a validation set. During training, the model's performance is evaluated on this validation set after each epoch. This helps to monitor for overfitting and tune hyperparameters.\n",
        "\n",
        "## Section 6: Model Evaluation - Assessing Performance on Test Data\n",
        "\n",
        "After training, we need to evaluate our model's performance on the test dataset.  This gives us an estimate of how well the model generalizes to unseen data.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1.  **Run the code cell below.**\n",
        "2.  **Observe the output.**  It will print the test loss and test accuracy.\n",
        "3.  **Think about the results.** Is the test accuracy satisfactory?  How does it compare to the training and validation accuracy you observed during training?"
      ],
      "metadata": {
        "id": "6FW7k1KMyabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Model Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0200\n",
            "Test accuracy: 0.9936\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "id": "f3KehXAlyabO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "77fb5604-0166-476f-deb1-f3a04325ff2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 7: Reflection and Answers to Questions\n",
        "This is an important section! Take some time to reflect on what you have learned and answer the following questions in detail. Your thoughtful answers will demonstrate your understanding of the concepts covered in this assignment.\n",
        "\n",
        "**Reflection Questions:**\n",
        "\n",
        "1.  **Conv2D Layer:** What is the role of the Conv2D layer? How do the `kernel_size` and the number of filters affect the learning process? *Hint: Experiment by changing these values in Cell 3.*\n",
        "\n",
        "- The Conv2D layer is my network’s feature extractor. It scans images using filters to detect edges, textures, and patterns. The kernel_size—for example, 3×3 versus 5×5—determines how much of the image each filter covers; smaller kernels capture fine details, while larger ones pick up more context. Increasing the number of filters (from 32 to 64 to 128) lets the model learn more features, speeding up convergence, though with MNIST the jump from 64 to 128 only gave marginal gains.\n",
        "\n",
        "2.  **MaxPooling2D Layer:** What is the purpose of the MaxPooling2D layer? How does it contribute to the model's performance?  *Hint:  Try removing or adding a MaxPooling2D layer and see what happens.*\n",
        "\n",
        "- MaxPooling2D downsamples the feature maps by taking the maximum value in each window (e.g., 2×2). This reduction decreases computation and makes the features less sensitive to small shifts in the image. In my experiments, adjusting the pooling layers changed the training speed and helped control overfitting by focusing on the most important features.\n",
        "\n",
        "3.  **One-Hot Encoding:** Why do we use one-hot encoding for the labels?\n",
        "\n",
        "- One-hot encoding converts the labels (digits 0–9) into a binary vector format, so each label becomes a vector with a single 1 and the rest 0s. This is essential for the softmax output in the final Dense layer, ensuring that every class is treated independently.\n",
        "\n",
        "\n",
        "4.  **Flatten Layer:** Why do we need the Flatten layer before the Dense layer?\n",
        "\n",
        "- The Flatten layer converts the multi-dimensional output of the Conv2D and pooling layers into a one-dimensional vector, which is necessary before feeding the data into the Dense layers for classification.\n",
        "\n",
        "5.  **Optimizer and Loss Function:** What optimizer and loss function did you choose in Cell 4? Explain your choices.  Why is categorical cross-entropy a suitable loss function for this task?  Why is Adam a good choice of optimiser?\n",
        "\n",
        "- I used categorical_crossentropy as the loss function and Adam as the optimizer. Categorical crossentropy works perfectly for multi-class tasks like MNIST, while Adam adapts the learning rate during training, leading to faster and more efficient convergence.\n",
        "\n",
        "6.  **Batch Size and Epochs:** How did you choose the batch size and number of epochs in Cell 5? What are the effects of changing these parameters?  *Hint:  Experiment!*\n",
        "\n",
        "- I set the batch size to 64 and trained for 15 epochs. A batch size of 64 strikes a good balance between fast training and stable updates, while 15 epochs were enough to let the model converge without overfitting. Experimenting with different sizes showed how these parameters can affect both training speed and generalization.\n",
        "\n",
        "7.  **Dropout:**  Why is the Dropout layer included in the model?\n",
        "\n",
        "- The Dropout layer randomly disables a percentage of neurons during training. This prevents overfitting by forcing the network to learn more robust, redundant features that generalize better to new data.\n",
        "\n",
        "8.  **Model Architecture:**  Describe the overall architecture of your CNN. How many convolutional layers did you use?  How many max pooling layers?  What is the final dense layer doing?\n",
        "\n",
        "My CNN architecture consists of:\n",
        "\n",
        "- Convolutional Layers: Three Conv2D layers (with configurations using 32, 64, or 128 filters in various experiments) for progressively extracting complex features.\n",
        "- Pooling Layers: Three MaxPooling2D layers to reduce spatial dimensions.\n",
        "- Flatten Layer: To convert 2D feature maps into a 1D vector.\n",
        "- Dropout Layer: To mitigate overfitting.\n",
        "- Dense Layers: A final Dense layer with softmax activation that outputs the probability for each of the 10 digit classes.\n",
        "\n",
        "9.  **Performance:** What accuracy did you achieve on the test set?  Are you happy with the result? Why or why not?  If you're not happy, what could you try to improve the performance?\n",
        "\n",
        "-Overall, I achieved around 98%–99% accuracy on the test set, which is solid for MNIST. This performance shows the model generalizes well. For further improvements, I might explore additional data augmentation, adjust learning rates, or try more advanced regularization techniques to push the accuracy even higher.\n",
        "\n",
        "**Tips and Explanations:**\n",
        "\n",
        "*   **Normalization:**  Dividing the pixel values by 255 normalizes them to the range [0, 1]. This is important for training neural networks.\n",
        "\n",
        "*   **Reshaping:**  The `reshape` operation adds a channel dimension to the images.  For grayscale images, the channel dimension is 1.\n",
        "\n",
        "*   **One-Hot Encoding:** `to_categorical` converts the class labels (0-9) into one-hot encoded vectors.\n",
        "\n",
        "*   **Conv2D Parameters:** The `kernel_size` determines the size of the convolutional filter (e.g., 3x3). The number of filters determines how many different features are learned.\n",
        "\n",
        "*   **MaxPooling2D Parameters:** The `pool_size` determines the size of the pooling window (e.g., 2x2).\n",
        "\n",
        "*   **Optimizer:** The optimizer is the algorithm used to update the model's weights during training.\n",
        "\n",
        "*   **Loss Function:** The loss function measures the error between the model's predictions and the true labels.\n",
        "\n",
        "*   **Batch Size:** The batch size is the number of samples processed in each training iteration.\n",
        "\n",
        "*   **Epochs:** An epoch is one complete pass through the entire training dataset.\n",
        "\n",
        "*   **Dropout:** Dropout is a regularization technique that helps prevent overfitting.\n",
        "\n",
        "Remember to run each cell to see its output.  Experiment with the code and try to understand how different parameters affect the model's performance.  Good luck!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VL_6FT9K5bBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Submission\n",
        " Congratulations on completing this notebook assignment! You have successfully built and trained a Convolutional Neural\n",
        " Network to classify handwritten digits from the MNIST dataset. You've explored key concepts like convolutional layers, pooling layers, activation functions, optimizers, loss functions, and training procedures. To further solidify your understanding, consider the following:\n",
        "*   **Review your notebook:** Go back through each section, reread the explanations, and make sure you understand the code and the concepts.\n",
        "*   **Experiment further:** Try different CNN architectures, add more layers, change hyperparameters, and see how it affects the performance. Explore other optimizers or loss functions.\n",
        "*   **Reflect on your learning:**  Think about the challenges you faced and how you overcame them. What were the most important takeaways for you from this assignment?\n",
        "\n",
        "**Submission Instructions**\n",
        "\n",
        "To submit your assignment:\n",
        "\n",
        "1.  **Save your notebook:** Ensure all your work, including code cells, outputs, and answers to reflection questions, is saved in the notebook.\n",
        "2.  **Print the notebook as a `.pdf` file** and submit it to Canvas.\n",
        "\n",
        "**Deadline:** February, 12th"
      ],
      "metadata": {
        "id": "e9_VbuuK6MFg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}